{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca7c6051",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b268cb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Iterator\n",
    "import tiktoken\n",
    "import textract\n",
    "from numpy import array, average\n",
    "\n",
    "from database import get_redis_connection\n",
    "\n",
    "# Set our default models and chunking size\n",
    "from config import COMPLETIONS_MODEL, EMBEDDINGS_MODEL, CHAT_MODEL, TEXT_EMBEDDING_CHUNK_SIZE, VECTOR_FIELD_NAME\n",
    "\n",
    "# Setup the API keys\n",
    "# openai.api_key = os.environ.get('OPENAI_API_KEY')\n",
    "openai.api_key = \"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\"\n",
    "# Ignore unclosed SSL socket warnings - optional in case you get these errors\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"unclosed\", category=ImportWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13ad2d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "791846a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Arun_Duggal_Faridabad_vs_Dcit_Central_Circle_1_on_4_January_2022.PDF',\n",
       " 'Assistant_Commissioner_Of_Income_vs_M_S_Hari_Narain_Parwal_Huf_on_24_February_2022.PDF',\n",
       " 'Astt_Commissioner_Of_Income_Tax_vs_M_S_U_P_Awas_Evam_Vikas_Parishad_on_8_June_2022.PDF',\n",
       " 'Eshita_Dye_Chem_Pvt_Ltd_Mumbai_vs_Assessee_on_25_January_1006.PDF',\n",
       " 'Fidelity_Mangaemtn_Research_Co_vs_Department_Of_Income_Tax_on_2_September_6648.PDF',\n",
       " 'Income_Tax_Officer_Jaipur_vs_Motisons_Jewellers_Ltdl_Jaipur_on_29_September_2022-1.PDF',\n",
       " 'Income_Tax_Officer_Jaipur_vs_Motisons_Jewellers_Ltdl_Jaipur_on_29_September_2022.PDF',\n",
       " 'Shri_Ramesh_Chand_Rai_Indore_vs_The_Cit_A_3_Bhopal_Bhopal_on_18_April_2022.PDF',\n",
       " 'Torrent_Pharmaceuticals_Ltd_vs_The_Deputy_Commissioner_Of_Income_on_22_February_2022.PDF',\n",
       " 'Young_Indian_New_Delhi_vs_Acit_E_New_Delhi_on_31_March_2022.PDF']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = os.path.join(os.curdir,'data_tax')\n",
    "pdf_files = sorted([x for x in os.listdir(data_dir) if 'DS_Store' not in x])\n",
    "pdf_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b1a9d3",
   "metadata": {},
   "source": [
    "## Setup Redis Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd4924e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Redis\n",
    "from redis import Redis\n",
    "from redis.commands.search.query import Query\n",
    "from redis.commands.search.field import (\n",
    "    TextField,\n",
    "    VectorField,\n",
    "    NumericField\n",
    ")\n",
    "from redis.commands.search.indexDefinition import (\n",
    "    IndexDefinition,\n",
    "    IndexType\n",
    ")\n",
    "\n",
    "redis_client = get_redis_connection()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5253bb",
   "metadata": {},
   "source": [
    "## Create an Index in redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d83dfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "VECTOR_DIM = 1536 #len(data['title_vector'][0]) # length of the vectors\n",
    "#VECTOR_NUMBER = len(data)                 # initial number of vectors\n",
    "PREFIX = \"taxdoc_v1\"                            # prefix for the document keys\n",
    "DISTANCE_METRIC = \"COSINE\"       \n",
    "# Index\n",
    "INDEX_NAME = \"tax-index-v1\"           # name of the search index\n",
    "VECTOR_FIELD_NAME = 'content_vector'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632d2962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create search index\n",
    "\n",
    "# Define RediSearch fields for each of the columns in the dataset\n",
    "# This is where you should add any additional metadata you want to capture\n",
    "# filename = TextField(\"filename\")\n",
    "# text_chunk = TextField(\"text_chunk\")\n",
    "# file_chunk_index = NumericField(\"file_chunk_index\")\n",
    "\n",
    "# # define RediSearch vector fields to use HNSW index\n",
    "\n",
    "# text_embedding = VectorField(VECTOR_FIELD_NAME,\n",
    "#     \"HNSW\", {\n",
    "#         \"TYPE\": \"FLOAT32\",\n",
    "#         \"DIM\": VECTOR_DIM,\n",
    "#         \"DISTANCE_METRIC\": DISTANCE_METRIC\n",
    "#     }\n",
    "# )\n",
    "# # Add all our field objects to a list to be created as an index\n",
    "# fields = [filename,text_chunk,file_chunk_index,text_embedding]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e697d34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "redis_client.ping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd031c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional step to drop the index if it already exists\n",
    "##redis_client.ft(INDEX_NAME).dropindex()\n",
    "\n",
    "# Check if index exists\n",
    "# try:\n",
    "#     redis_client.ft(INDEX_NAME).info()\n",
    "#     print(\"Index already exists\")\n",
    "# except Exception as e:\n",
    "#     print(e)\n",
    "#     # Create RediSearch Index\n",
    "#     print('Not there yet. Creating')\n",
    "#     redis_client.ft(INDEX_NAME).create_index(\n",
    "#         fields = fields,\n",
    "#         definition = IndexDefinition(prefix=[PREFIX], index_type=IndexType.HASH)\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49e50baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from database import create_hnsw_index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "189ac8b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ResponseError",
     "evalue": "Index already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResponseError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mcreate_hnsw_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mredis_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43mVECTOR_FIELD_NAME\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mVECTOR_DIM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDISTANCE_METRIC\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\openai\\apps\\chatbot-kickstarter\\database.py:22\u001b[0m, in \u001b[0;36mcreate_hnsw_index\u001b[1;34m(redis_conn, vector_field_name, vector_dimensions, distance_metric)\u001b[0m\n\u001b[0;32m     20\u001b[0m # Create a Redis index to hold our data\n\u001b[0;32m     21\u001b[0m def create_hnsw_index (redis_conn,vector_field_name,vector_dimensions=1536, distance_metric='COSINE'):\n\u001b[1;32m---> 22\u001b[0m     redis_conn.ft(INDEX_NAME).create_index(field = [\n\u001b[0;32m     23\u001b[0m         VectorField(vector_field_name, \"HNSW\", {\"TYPE\": \"FLOAT32\", \"DIM\": vector_dimensions, \"DISTANCE_METRIC\": distance_metric}),\n\u001b[0;32m     24\u001b[0m         TextField(\"filename\"),\n",
      "File \u001b[1;32mD:\\openai\\apps\\chatbot-kickstarter\\env\\lib\\site-packages\\redis\\commands\\search\\commands.py:141\u001b[0m, in \u001b[0;36mSearchCommands.create_index\u001b[1;34m(self, fields, no_term_offsets, no_field_flags, stopwords, definition, max_text_fields, temporary, no_highlight, no_term_frequencies, skip_initial_scan)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    139\u001b[0m     args \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m fields\u001b[38;5;241m.\u001b[39mredis_args()\n\u001b[1;32m--> 141\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_command\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\openai\\apps\\chatbot-kickstarter\\env\\lib\\site-packages\\redis\\client.py:1258\u001b[0m, in \u001b[0;36mRedis.execute_command\u001b[1;34m(self, *args, **options)\u001b[0m\n\u001b[0;32m   1255\u001b[0m conn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnection \u001b[38;5;129;01mor\u001b[39;00m pool\u001b[38;5;241m.\u001b[39mget_connection(command_name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m   1257\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1258\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1259\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_command_parse_response\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1260\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcommand_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\n\u001b[0;32m   1261\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1262\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_disconnect_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1263\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1264\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1265\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnection:\n",
      "File \u001b[1;32mD:\\openai\\apps\\chatbot-kickstarter\\env\\lib\\site-packages\\redis\\retry.py:46\u001b[0m, in \u001b[0;36mRetry.call_with_retry\u001b[1;34m(self, do, fail)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 46\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdo\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_supported_errors \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[0;32m     48\u001b[0m         failures \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mD:\\openai\\apps\\chatbot-kickstarter\\env\\lib\\site-packages\\redis\\client.py:1259\u001b[0m, in \u001b[0;36mRedis.execute_command.<locals>.<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m   1255\u001b[0m conn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnection \u001b[38;5;129;01mor\u001b[39;00m pool\u001b[38;5;241m.\u001b[39mget_connection(command_name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m   1257\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1258\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mretry\u001b[38;5;241m.\u001b[39mcall_with_retry(\n\u001b[1;32m-> 1259\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_command_parse_response(\n\u001b[0;32m   1260\u001b[0m             conn, command_name, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1261\u001b[0m         ),\n\u001b[0;32m   1262\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m error: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_disconnect_raise(conn, error),\n\u001b[0;32m   1263\u001b[0m     )\n\u001b[0;32m   1264\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1265\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnection:\n",
      "File \u001b[1;32mD:\\openai\\apps\\chatbot-kickstarter\\env\\lib\\site-packages\\redis\\client.py:1235\u001b[0m, in \u001b[0;36mRedis._send_command_parse_response\u001b[1;34m(self, conn, command_name, *args, **options)\u001b[0m\n\u001b[0;32m   1231\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1232\u001b[0m \u001b[38;5;124;03mSend a command and parse the response\u001b[39;00m\n\u001b[0;32m   1233\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1234\u001b[0m conn\u001b[38;5;241m.\u001b[39msend_command(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m-> 1235\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_response(conn, command_name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[1;32mD:\\openai\\apps\\chatbot-kickstarter\\env\\lib\\site-packages\\redis\\client.py:1275\u001b[0m, in \u001b[0;36mRedis.parse_response\u001b[1;34m(self, connection, command_name, **options)\u001b[0m\n\u001b[0;32m   1273\u001b[0m         options\u001b[38;5;241m.\u001b[39mpop(NEVER_DECODE)\n\u001b[0;32m   1274\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1275\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1276\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ResponseError:\n\u001b[0;32m   1277\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m EMPTY_RESPONSE \u001b[38;5;129;01min\u001b[39;00m options:\n",
      "File \u001b[1;32mD:\\openai\\apps\\chatbot-kickstarter\\env\\lib\\site-packages\\redis\\connection.py:957\u001b[0m, in \u001b[0;36mConnection.read_response\u001b[1;34m(self, disable_decoding)\u001b[0m\n\u001b[0;32m    954\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnext_health_check \u001b[38;5;241m=\u001b[39m time() \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhealth_check_interval\n\u001b[0;32m    956\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, ResponseError):\n\u001b[1;32m--> 957\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m response\n\u001b[0;32m    958\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[1;31mResponseError\u001b[0m: Index already exists"
     ]
    }
   ],
   "source": [
    "create_hnsw_index(redis_client,VECTOR_FIELD_NAME, VECTOR_DIM, DISTANCE_METRIC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a55a892",
   "metadata": {},
   "source": [
    "### Ingestion\n",
    "\n",
    "We'll load up our PDFs and do the following\n",
    "\n",
    "    Initiate our tokenizer\n",
    "    Run a processing pipeline to:\n",
    "        Mine the text from each PDF\n",
    "        Split them into chunks and embed them\n",
    "        Store them in Redi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2523108",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import handle_file_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f272a130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\data_tax\\Arun_Duggal_Faridabad_vs_Dcit_Central_Circle_1_on_4_January_2022.PDF\n",
      ".\\data_tax\\Assistant_Commissioner_Of_Income_vs_M_S_Hari_Narain_Parwal_Huf_on_24_February_2022.PDF\n",
      ".\\data_tax\\Astt_Commissioner_Of_Income_Tax_vs_M_S_U_P_Awas_Evam_Vikas_Parishad_on_8_June_2022.PDF\n",
      ".\\data_tax\\Eshita_Dye_Chem_Pvt_Ltd_Mumbai_vs_Assessee_on_25_January_1006.PDF\n",
      ".\\data_tax\\Fidelity_Mangaemtn_Research_Co_vs_Department_Of_Income_Tax_on_2_September_6648.PDF\n",
      ".\\data_tax\\Income_Tax_Officer_Jaipur_vs_Motisons_Jewellers_Ltdl_Jaipur_on_29_September_2022-1.PDF\n",
      ".\\data_tax\\Income_Tax_Officer_Jaipur_vs_Motisons_Jewellers_Ltdl_Jaipur_on_29_September_2022.PDF\n",
      ".\\data_tax\\Shri_Ramesh_Chand_Rai_Indore_vs_The_Cit_A_3_Bhopal_Bhopal_on_18_April_2022.PDF\n",
      ".\\data_tax\\Torrent_Pharmaceuticals_Ltd_vs_The_Deputy_Commissioner_Of_Income_on_22_February_2022.PDF\n",
      ".\\data_tax\\Young_Indian_New_Delhi_vs_Acit_E_New_Delhi_on_31_March_2022.PDF\n",
      "CPU times: total: 34.9 s\n",
      "Wall time: 1min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# This step takes about 5 minutes\n",
    "\n",
    "# Initialise tokenizer\n",
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "# Process each PDF file and prepare for embedding\n",
    "for pdf_file in pdf_files:\n",
    "    \n",
    "    pdf_path = os.path.join(data_dir,pdf_file)\n",
    "    print(pdf_path)\n",
    "    \n",
    "    # Extract the raw text from each PDF using textract\n",
    "    text = textract.process(pdf_path, method='pdftotext')\n",
    "    \n",
    "    # Chunk each document, embed the contents and load to Redis\n",
    "    handle_file_string((pdf_file,text.decode(\"utf-8\")),tokenizer,redis_client,VECTOR_FIELD_NAME,INDEX_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "18117ac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2749'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that our docs have been inserted\n",
    "redis_client.ft(\"idx\").info()['num_docs']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66c330e",
   "metadata": {},
   "source": [
    "## Search in the Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e8b7bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from database import get_redis_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8ee5441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 31.2 ms\n",
      "Wall time: 754 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>result</th>\n",
       "      <th>certainty</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>\\r  167 At the outset, we note that the issue raised by the Revenue in its ground of appeal for the AY 2011-12 is identical to the issue raised by the assessee vide ground no. 1 in ITA No. 1285/AHD/2017 for the assessment year 2009- 10 and ground no. 2 in ITA No. 1286/Ahd/2017 for A.Y. 2010-11 Therefore, the findings given in ITA No. 1285 and 1286/AHD/2017 shall also be applicable for the year under consideration i.e. AY 2011-12. The appeal of the Assessee for the assessment 2009-10 and 2010-11 has been decided by us vide paragraph Nos. 12 and 84 of this order and has been decided in favour of the assessee. The learned AR and the DR also agreed that whatever will be the findings for the assessment year 2009-10 and 2010-11 shall also be applied for the year under consideration i.e. AY 2011-12. Hence, the grounds of appeal filed by the Revenue is hereby dismissed.\\r  168. In the result appeal of the Revenue is dismissed.\\r  Coming to ITA No. 1397/AHD/2018, an appeal by the assessee for the AY 2012-13 ITA.Nos.1285/Ahd/2017 &amp; 7 others A.Y.2009-10\\r  169. The assessee has raised following grounds of appeal:\\r  1. On the facts and in the circumstances of the case, the learned CIT(Appeals) erred in confirming disallowance of Rs.7,26,245 made by the Assessing Officer in respect of Employees Provident Fund and ESI contributions on the ground that these payments were made by the appellant company beyond the time limit prescribed under the relevant provisions of PF and ESIC Acts.</td>\n",
       "      <td>0.0786235928535</td>\n",
       "      <td>Torrent_Pharmaceuticals_Ltd_vs_The_Deputy_Commissioner_Of_Income_on_22_February_2022.PDF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>\\r  \\r  123. At the outset, we note that the issue raised by the Revenue in its ground of appeal for the AY 2010-11 is identical to the issue raised by the Revenue vide ground no. 8 in ITA No. 1327/AHD/2017 for the assessment year 2009-\\r  \\r  Indian Kanoon - http://indiankanoon.org/doc/167968689/\\r  \\r  66\\r  \\r  \f",
       "Torrent Pharmaceuticals Ltd.,, ... vs The Deputy Commissioner Of Income ... on 22 February, 2022\\r  10. Therefore, the findings given in ITA No. 1327/AHD/2017 shall also be applicable for the year under consideration i.e. AY 2010-11. The ground of appeal of the Revenue for the assessment 2009-10 has been decided by us vide paragraph Nos. 72 of this order against the Revenue. The learned AR and the DR also agreed that whatever will be the findings for the assessment year 2009-10 shall also be applied for the year under consideration i.e. AY 2010-\\r  \\r  11. Hence, the ground of appeal filed by the Revenue is hereby dismissed.\\r  \\r  ITA.Nos.1285/Ahd/2017 &amp; 7 others A.Y.2009-10\\r  \\r  124. In the result appeal of the Revenue is dismissed.\\r  \\r  Coming to ITA No. 1396/AHD/2018, an appeal by the Assessee for the AY 2011-12\\r  \\r  125. The assessee has raised following grounds of appeal\\r  \\r  1. On the facts and in the circumstances of the case, the learned CIT(Appeals) erred in confirming the addition of Rs.</td>\n",
       "      <td>0.0796328783035</td>\n",
       "      <td>Torrent_Pharmaceuticals_Ltd_vs_The_Deputy_Commissioner_Of_Income_on_22_February_2022.PDF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  \\\n",
       "0  0    \n",
       "1  1    \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  result  \\\n",
       "0  \\r  167 At the outset, we note that the issue raised by the Revenue in its ground of appeal for the AY 2011-12 is identical to the issue raised by the assessee vide ground no. 1 in ITA No. 1285/AHD/2017 for the assessment year 2009- 10 and ground no. 2 in ITA No. 1286/Ahd/2017 for A.Y. 2010-11 Therefore, the findings given in ITA No. 1285 and 1286/AHD/2017 shall also be applicable for the year under consideration i.e. AY 2011-12. The appeal of the Assessee for the assessment 2009-10 and 2010-11 has been decided by us vide paragraph Nos. 12 and 84 of this order and has been decided in favour of the assessee. The learned AR and the DR also agreed that whatever will be the findings for the assessment year 2009-10 and 2010-11 shall also be applied for the year under consideration i.e. AY 2011-12. Hence, the grounds of appeal filed by the Revenue is hereby dismissed.\\r  168. In the result appeal of the Revenue is dismissed.\\r  Coming to ITA No. 1397/AHD/2018, an appeal by the assessee for the AY 2012-13 ITA.Nos.1285/Ahd/2017 & 7 others A.Y.2009-10\\r  169. The assessee has raised following grounds of appeal:\\r  1. On the facts and in the circumstances of the case, the learned CIT(Appeals) erred in confirming disallowance of Rs.7,26,245 made by the Assessing Officer in respect of Employees Provident Fund and ESI contributions on the ground that these payments were made by the appellant company beyond the time limit prescribed under the relevant provisions of PF and ESIC Acts.   \n",
       "1  \\r  \\r  123. At the outset, we note that the issue raised by the Revenue in its ground of appeal for the AY 2010-11 is identical to the issue raised by the Revenue vide ground no. 8 in ITA No. 1327/AHD/2017 for the assessment year 2009-\\r  \\r  Indian Kanoon - http://indiankanoon.org/doc/167968689/\\r  \\r  66\\r  \\r  \n",
       "Torrent Pharmaceuticals Ltd.,, ... vs The Deputy Commissioner Of Income ... on 22 February, 2022\\r  10. Therefore, the findings given in ITA No. 1327/AHD/2017 shall also be applicable for the year under consideration i.e. AY 2010-11. The ground of appeal of the Revenue for the assessment 2009-10 has been decided by us vide paragraph Nos. 72 of this order against the Revenue. The learned AR and the DR also agreed that whatever will be the findings for the assessment year 2009-10 shall also be applied for the year under consideration i.e. AY 2010-\\r  \\r  11. Hence, the ground of appeal filed by the Revenue is hereby dismissed.\\r  \\r  ITA.Nos.1285/Ahd/2017 & 7 others A.Y.2009-10\\r  \\r  124. In the result appeal of the Revenue is dismissed.\\r  \\r  Coming to ITA No. 1396/AHD/2018, an appeal by the Assessee for the AY 2011-12\\r  \\r  125. The assessee has raised following grounds of appeal\\r  \\r  1. On the facts and in the circumstances of the case, the learned CIT(Appeals) erred in confirming the addition of Rs.                                                                                                                                                              \n",
       "\n",
       "         certainty  \\\n",
       "0  0.0786235928535   \n",
       "1  0.0796328783035   \n",
       "\n",
       "                                                                                   filename  \n",
       "0  Torrent_Pharmaceuticals_Ltd_vs_The_Deputy_Commissioner_Of_Income_on_22_February_2022.PDF  \n",
       "1  Torrent_Pharmaceuticals_Ltd_vs_The_Deputy_Commissioner_Of_Income_on_22_February_2022.PDF  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "prompt = \"Grounds of appeal raised by the Revenue for AY 2010-11 in IT(SS)A No.49/Ind/2021\"\n",
    "result_df = get_redis_results(redis_client,prompt,index_name=\"idx\")\n",
    "result_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b122110",
   "metadata": {},
   "source": [
    "## Use chat gpt to search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cce3e5a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' -Issue of ground of appeal raised by Revenue for AY 2010-11 is same as ITA No. 1285/Ahd/2017 & 1286/Ahd/2017 for AY 2009-10 and 2010-11.\\n     -Ground of appeal by Revenue dismissed as the findings in ITA No. 1285&1286/Ahd/2017 would apply to AY 2011-12.\\n     -Appeal by Assessee for AY 2012-13 raised ground of disallowance for Rs.7,26,245 made by Assessing Officer for Employees Provident Fund and ESI contributions made beyond the time limit prescribed.'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_prompt = '''Summarise this result in a bulleted list to answer the search query a customer has sent.\n",
    "    Search query: SEARCH_QUERY_HERE\n",
    "    Search result: SEARCH_RESULT_HERE\n",
    "    Summary:\n",
    "    '''\n",
    "summary_prepped = summary_prompt.replace('SEARCH_QUERY_HERE',prompt).replace('SEARCH_RESULT_HERE',result_df['result'][0])\n",
    "summary = openai.Completion.create(engine=COMPLETIONS_MODEL,prompt=summary_prepped,max_tokens=500)\n",
    "summary['choices'][0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d80606",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
